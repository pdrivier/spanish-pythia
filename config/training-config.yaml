train_batch_size: 4
eval_batch_size: 4
gradient_accumulation_steps: 8
num_train_epochs: 1
max_train_steps: 150000
learning_rate: 0.00005
weight_decay: 0.01
warmup_steps: 100
save_steps: 5000
eval_steps: 5000
logging_steps: 50
save_total_limit: 3
output_dir: "./outputs"
fp16: true
